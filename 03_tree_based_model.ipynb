{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 03 \u2014 Tree-Based Model (XGBoost)\n",
        "\n",
        "Goal:\n",
        "- train a strong non-linear model (XGBoost) to capture feature interactions\n",
        "- evaluate with **Precision\u2013Recall (PR-AUC)**\n",
        "- save predicted probabilities + `amount` for expected loss analysis (next notebook)\n",
        "\n",
        "**Why XGBoost here?**\n",
        "- captures non-linear interactions in latent PCA feature space\n",
        "- strong for tabular risk scoring\n",
        "- supports imbalance via `scale_pos_weight`\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import precision_recall_curve, average_precision_score, roc_auc_score\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "DATA_PATH = '../data/creditcard.csv'\n",
        "df = pd.read_csv(DATA_PATH)\n",
        "cols = list(df.columns)\n",
        "label_col = 'Class' if 'Class' in cols else 'class'\n",
        "time_col  = 'Time'  if 'Time'  in cols else 'time'\n",
        "amount_col= 'Amount' if 'Amount' in cols else 'amount'\n",
        "\n",
        "df[label_col] = pd.to_numeric(df[label_col], errors='coerce').fillna(0).astype(int)\n",
        "\n",
        "X = df.drop(columns=[label_col])\n",
        "y = df[label_col].astype(int)\n",
        "amount_all = df[amount_col].astype(float).values\n",
        "\n",
        "X_train, X_test, y_train, y_test, amt_train, amt_test = train_test_split(\n",
        "    X, y, amount_all, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "print('Train fraud rate:', y_train.mean())\n",
        "print('Test  fraud rate:', y_test.mean())"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "neg = (y_train == 0).sum()\n",
        "pos = (y_train == 1).sum()\n",
        "scale_pos_weight = neg / max(pos, 1)\n",
        "scale_pos_weight"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Train/validation split for early stopping\n",
        "X_tr, X_val, y_tr, y_val = train_test_split(\n",
        "    X_train, y_train, test_size=0.2, random_state=42, stratify=y_train\n",
        ")\n",
        "\n",
        "xgb = XGBClassifier(\n",
        "    n_estimators=2000,\n",
        "    learning_rate=0.05,\n",
        "    max_depth=4,\n",
        "    subsample=0.8,\n",
        "    colsample_bytree=0.8,\n",
        "    min_child_weight=1,\n",
        "    reg_alpha=0.0,\n",
        "    reg_lambda=1.0,\n",
        "    gamma=0.0,\n",
        "    objective='binary:logistic',\n",
        "    eval_metric='aucpr',\n",
        "    scale_pos_weight=scale_pos_weight,\n",
        "    tree_method='hist',\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "xgb.fit(\n",
        "    X_tr, y_tr,\n",
        "    eval_set=[(X_val, y_val)],\n",
        "    verbose=50,\n",
        "    early_stopping_rounds=50\n",
        ")\n",
        "\n",
        "proba_test = xgb.predict_proba(X_test)[:, 1]\n",
        "ap = average_precision_score(y_test, proba_test)\n",
        "auc = roc_auc_score(y_test, proba_test)\n",
        "print(f'XGBoost PR-AUC (Average Precision): {ap:.4f}')\n",
        "print(f'XGBoost ROC-AUC: {auc:.4f}')"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "precision, recall, thresholds = precision_recall_curve(y_test, proba_test)\n",
        "plt.figure()\n",
        "plt.plot(recall, precision)\n",
        "plt.title('Precision\u2013Recall Curve (XGBoost)')\n",
        "plt.xlabel('Recall')\n",
        "plt.ylabel('Precision')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Save artifacts for next notebook\n",
        "artifacts = pd.DataFrame({'y_true': y_test.values, 'proba': proba_test, 'amount': amt_test})\n",
        "artifacts.to_csv('../data/xgb_test_scoring.csv', index=False)\n",
        "print('Saved ../data/xgb_test_scoring.csv')\n",
        "\n",
        "pd.Series(X.columns).to_csv('../data/feature_names.csv', index=False, header=False)\n",
        "print('Saved ../data/feature_names.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Next: Notebook 04 selects thresholds by **expected loss** and defines an Allow/Flag/Block policy.\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}