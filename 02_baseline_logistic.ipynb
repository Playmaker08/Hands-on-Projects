{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 02 \u2014 Baseline Logistic Regression (Probability-First)\n",
        "\n",
        "Baseline model:\n",
        "- Standardize features\n",
        "- Logistic regression with class weights\n",
        "- Evaluate with PR curve + PR-AUC\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import precision_recall_curve, average_precision_score, roc_auc_score\n",
        "\n",
        "df = pd.read_csv('../data/creditcard.csv')\n",
        "cols = list(df.columns)\n",
        "label_col = 'Class' if 'Class' in cols else 'class'\n",
        "df[label_col] = pd.to_numeric(df[label_col], errors='coerce').fillna(0).astype(int)\n",
        "\n",
        "X = df.drop(columns=[label_col])\n",
        "y = df[label_col]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "print('Train fraud rate:', y_train.mean())\n",
        "print('Test fraud rate :', y_test.mean())"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "pipe = Pipeline([\n",
        "    ('scaler', StandardScaler()),\n",
        "    ('clf', LogisticRegression(max_iter=2000, class_weight='balanced'))\n",
        "])\n",
        "pipe.fit(X_train, y_train)\n",
        "proba = pipe.predict_proba(X_test)[:, 1]\n",
        "\n",
        "ap = average_precision_score(y_test, proba)\n",
        "auc = roc_auc_score(y_test, proba)\n",
        "print(f'PR-AUC (Average Precision): {ap:.4f}')\n",
        "print(f'ROC-AUC: {auc:.4f}')"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "precision, recall, thresholds = precision_recall_curve(y_test, proba)\n",
        "plt.figure()\n",
        "plt.plot(recall, precision)\n",
        "plt.title('Precision\u2013Recall Curve (Baseline)')\n",
        "plt.xlabel('Recall')\n",
        "plt.ylabel('Precision')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Next notebook: train a tree-based model (XGBoost) and compare PR-AUC.\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}